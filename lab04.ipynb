{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f38b78-6729-430c-b6e1-ade296def696",
   "metadata": {},
   "source": [
    "# Lab 4: Collaborative Filtering Recommender Systems\n",
    "\n",
    "This lab implements the collaborative filtering learning algorithm and applies it to a dataset of movie ratings. \n",
    "\n",
    "The goal of a collaborative filtering recommender system is to generate two vectors: \n",
    "* For each user, a 'parameter vector' that embodies the movie tastes of a user.\n",
    "* For each movie, a feature vector of the same size which embodies some description of the movie.\n",
    "* The dot product of the two vectors plus the bias term should produce an estimate of the rating the user might give to that movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2369830e-bd3e-4145-9701-13203d748f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from lib.recsys_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038635ae-0e47-4f58-ac85-caa75e52a0ab",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "*The data set is derived from the [MovieLens \"ml-latest-small\"](https://grouplens.org/datasets/movielens/latest/) dataset.   \n",
    "[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1â€“19:19. <https://doi.org/10.1145/2827872>]*\n",
    "\n",
    "We use a subset of the original dataset.\n",
    "* The original dataset has 9000 movies rated by 600 users.\n",
    "* The dataset has been reduced in size to focus on movies from the years since 2000.\n",
    "* The reduced dataset has $n_u = 443$ users, and $n_m= 4778$ movies.\n",
    "\n",
    "Aspects of the dataset:\n",
    "* Existing ratings are provided in matrix Y. Ratings range from 0.5 to 5 inclusive in 0.5 steps. 0 if the movie has not been rated.\n",
    "* R matrix indicates whether or not a user has rated a movie. 1 for rated. Movies are in rows, users in columns.\n",
    "* Each user has a parameter vector (W)and bias (b).\n",
    "* Each movie has a feature vector (X). These vectors are simultaneously learned by using the existing user/movie ratings as training data. Once the feature vectors and parameters are learned, they can be used to predict how a user might rate an unrated movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862b904e-699b-4d76-87d7-5a11385c33f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (4778, 443) R (4778, 443)\n",
      "X (4778, 10)\n",
      "W (443, 10)\n",
      "b (1, 443)\n",
      "num_features 10\n",
      "num_movies 4778\n",
      "num_users 443\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "X, W, b, num_movies, num_features, num_users = load_precalc_params_small()\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape)\n",
    "print(\"W\", W.shape)\n",
    "print(\"b\", b.shape)\n",
    "print(\"num_features\", num_features)\n",
    "print(\"num_movies\",   num_movies)\n",
    "print(\"num_users\",    num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e67859-9553-4714-9e68-f948ca9d6848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for movie 1 : 3.400 / 5\n"
     ]
    }
   ],
   "source": [
    "#  From the matrix, we can compute statistics like average rating.\n",
    "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
    "print(f\"Average rating for movie 1 : {tsmean:0.3f} / 5\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ccd458-17a3-407e-8abc-4d3335918144",
   "metadata": {},
   "source": [
    "## Implement loss function for collaborative filtering\n",
    "\n",
    "This section implements the function `cofiCostFunc` that computes the collaborative filtering objective function. After implementing the objective function, we use a TensorFlow custom training loop to learn the parameters for collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ad193-6d8c-47f4-be29-1748cf5b547d",
   "metadata": {},
   "source": [
    "### Without vectorization or regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d26fc92-e9da-484e-bfa3-888656289547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: cofi_cost_func\n",
    "# UNQ_C1\n",
    "\n",
    "def cofi_cost_func_not_regularized(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "      \n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape # Y.shape: movie_count, user_count\n",
    "    J = 0\n",
    "    ### START CODE HERE ###  \n",
    "    \n",
    "    # Summation round 1 (over each user)\n",
    "    for i in range(nu):\n",
    "        w = W[i, :]\n",
    "        b_i = b[0, i]\n",
    "\n",
    "        # Summation round 2 (over each movie)\n",
    "        for j in range(nm):\n",
    "            x = X[j, :] \n",
    "            y = Y[j, i] # labelled rating\n",
    "            r = R[j, i] # used to turn on/off the cost because 0 if this movie not rated by this user\n",
    "\n",
    "            # Make prediction of review for this user/movie combination.\n",
    "            y_hat = np.dot(w, x) + b_i       \n",
    "\n",
    "            # Calculate loss as the squared difference between the prediction (y_hat) to the actual review (y)\n",
    "            squared_loss = (r * (y_hat - y))**2\n",
    "\n",
    "            # Add the loss for this user/movie combination to the overall loss\n",
    "            J += squared_loss\n",
    "\n",
    "    # Why are we dividing by 2 instead of dividing by 2*count?\n",
    "    J /= 2\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4372d3f1-dc8d-482f-9d74-d1fb86d1ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (without regularization): 13.67\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CUSTOM NON-REGULARIZED FUNCTION\n",
    "\n",
    "# Reduce the data set size so that this runs faster\n",
    "num_users_r = 4\n",
    "num_movies_r = 5 \n",
    "num_features_r = 3\n",
    "\n",
    "X_r = X[:num_movies_r, :num_features_r]\n",
    "W_r = W[:num_users_r,  :num_features_r]\n",
    "b_r = b[0, :num_users_r].reshape(1,-1)\n",
    "Y_r = Y[:num_movies_r, :num_users_r]\n",
    "R_r = R[:num_movies_r, :num_users_r]\n",
    "\n",
    "# Evaluate cost function\n",
    "J = cofi_cost_func_not_regularized(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost (without regularization): {J:0.2f}\")\n",
    "\n",
    "# Expected Cost when lambda = 0 (no regularization): 13.67"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b032788-cbdd-4620-8830-7b89f60a1aa2",
   "metadata": {},
   "source": [
    "### Without vectorization, with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5be58ea1-4f4a-4004-b5cf-bd47c1ca4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: cofi_cost_func\n",
    "# UNQ_C1\n",
    "\n",
    "# Regularized Version\n",
    "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "      \n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape # Y.shape: movie_count, user_count\n",
    "    J = 0\n",
    "    ### START CODE HERE ###  \n",
    "    \n",
    "    # Summation round 1 (over each user)\n",
    "    for i in range(nu):\n",
    "        w = W[i, :]\n",
    "        b_i = b[0, i]\n",
    "\n",
    "        # Summation round 2 (over each movie)\n",
    "        for j in range(nm):\n",
    "            x = X[j, :] \n",
    "            y = Y[j, i] # labelled rating\n",
    "            r = R[j, i] # used to turn on/off the cost because 0 if this movie not rated by this user\n",
    "\n",
    "            # Make prediction of review for this user/movie combination.\n",
    "            y_hat = np.dot(w, x) + b_i       \n",
    "\n",
    "            # Calculate loss as the squared difference between the prediction (y_hat) to the actual review (y)\n",
    "            squared_loss = (r * (y_hat - y))**2\n",
    "\n",
    "            # Add the loss for this user/movie combination to the overall loss\n",
    "            J += squared_loss\n",
    "\n",
    "    # Why are we dividing by 2 instead of dividing by 2*count?\n",
    "    J /= 2\n",
    "\n",
    "    # To regularize the data: \n",
    "    #    Square each element of the W array and X array. \n",
    "    #    Then sums all the squared elements. \n",
    "    # In previous work this was implemented with a loop but we can use numpy to vectorize the implementation.\n",
    "    J += (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))\n",
    "\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "760d922f-2330-409d-bf54-c7b8dfd2802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (without regularization): 13.67\n",
      "Cost (with regularization): 28.09\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CUSTOM REGULARIZED FUNCTION\n",
    "\n",
    "# Reduce the data set size so that this runs faster\n",
    "num_users_r = 4\n",
    "num_movies_r = 5 \n",
    "num_features_r = 3\n",
    "\n",
    "X_r = X[:num_movies_r, :num_features_r]\n",
    "W_r = W[:num_users_r,  :num_features_r]\n",
    "b_r = b[0, :num_users_r].reshape(1,-1)\n",
    "Y_r = Y[:num_movies_r, :num_users_r]\n",
    "R_r = R[:num_movies_r, :num_users_r]\n",
    "\n",
    "# Evaluate cost function WITHOUT REGULARIZATION (lambda = 0)\n",
    "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost (without regularization): {J:0.2f}\")\n",
    "# Expected Cost without regularization: 13.67\n",
    "\n",
    "\n",
    "# Evaluate cost function WITH REGULARIZATION (lambda = 1.5) \n",
    "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")\n",
    "\n",
    "# Should be higher than 13.67 (cost without regularization) because the regularization prevents over-fitting to the training set.\n",
    "# Expected Output: 28.09 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffb56edd-ed49-49ca-8e04-af858a791b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Public tests\n",
    "from public_tests import *\n",
    "test_cofi_cost_func(cofi_cost_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d1de1-a151-46ff-ad19-384bb619e30a",
   "metadata": {},
   "source": [
    "### With vectorization and regularization\n",
    "\n",
    "This is important because we will call the method repeatedly to optimize the parameters / minimize loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c1ac7b8-146f-4126-a247-dbbbd0dab3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_vectorized(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39e1bd8c-68f5-489b-8fba-98bcaa659faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (without regularization): 13.67\n",
      "Cost (with regularization): 28.09\n"
     ]
    }
   ],
   "source": [
    "# Evaluate cost function with vectorization but without regularization (lambda=0)\n",
    "J = cofi_cost_func_vectorized(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost (without regularization): {J:0.2f}\")\n",
    "# Expected Output: 13.67\n",
    "\n",
    "# Evaluate cost function with vectorization and regularization \n",
    "J = cofi_cost_func_vectorized(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")\n",
    "# Expected Output: 28.09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec87ed-ad91-4fae-8147-7cfccca2ebcc",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "183d0f7c-b0fb-4e42-86fe-ad79f8f4f1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  Shrek (2001)\n",
      "Rated 5.0 for  Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Rated 2.0 for  Amelie (Fabuleux destin d'AmÃ©lie Poulain, Le) (2001)\n",
      "Rated 5.0 for  Harry Potter and the Chamber of Secrets (2002)\n",
      "Rated 5.0 for  Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Rated 5.0 for  Lord of the Rings: The Return of the King, The (2003)\n",
      "Rated 3.0 for  Eternal Sunshine of the Spotless Mind (2004)\n",
      "Rated 5.0 for  Incredibles, The (2004)\n",
      "Rated 2.0 for  Persuasion (2007)\n",
      "Rated 5.0 for  Toy Story 3 (2010)\n",
      "Rated 3.0 for  Inception (2010)\n",
      "Rated 1.0 for  Louis Theroux: Law & Disorder (2008)\n",
      "Rated 1.0 for  Nothing to Declare (Rien Ã  dÃ©clarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "movieList, movieList_df = load_Movie_List_pd()\n",
    "\n",
    "my_ratings = np.zeros(num_movies)          #  Initialize my ratings\n",
    "\n",
    "# Check the file small_movie_list.csv for id of each movie in our dataset\n",
    "# For example, Toy Story 3 (2010) has ID 2700, so to rate it \"5\", you can set\n",
    "my_ratings[2700] = 5 \n",
    "\n",
    "#Or suppose you did not enjoy Persuasion (2007), you can set\n",
    "my_ratings[2609] = 2;\n",
    "\n",
    "# We have selected a few movies we liked / did not like and the ratings we\n",
    "# gave are as follows:\n",
    "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
    "my_ratings[246]  = 5   # Shrek (2001)\n",
    "my_ratings[2716] = 3   # Inception\n",
    "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
    "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'AmÃ©lie Poulain, Le)\n",
    "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
    "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
    "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
    "my_ratings[2937] = 1   # Nothing to Declare (Rien Ã  dÃ©clarer)\n",
    "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3acc55a2-3b73-4682-a5bb-efcc99c03c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload ratings\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "# Add new user ratings to Y \n",
    "Y = np.c_[my_ratings, Y]\n",
    "\n",
    "# Add new user indicator matrix to R\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "# Normalize the Dataset\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c293a-1f2e-4533-bae6-310bde4005d9",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "We will use tensorflow and the manually coded cost function in the previous section to optimize the paremeters (X, W, b) by mininimizing the costfunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fccf5dab-66f8-4f39-bd58-f529a5200455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16e4c691-0d30-4ffb-843b-1a7884cbb9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 2321191.3\n",
      "Training loss at iteration 20: 136169.3\n",
      "Training loss at iteration 40: 51863.7\n",
      "Training loss at iteration 60: 24599.0\n",
      "Training loss at iteration 80: 13630.6\n",
      "Training loss at iteration 100: 8487.7\n",
      "Training loss at iteration 120: 5807.8\n",
      "Training loss at iteration 140: 4311.6\n",
      "Training loss at iteration 160: 3435.3\n",
      "Training loss at iteration 180: 2902.1\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    \n",
    "    # Use Tensorflow's GradientTape to record the steps of calculating the cost function (J).\n",
    "    # This tape enables differentiation... which we need in the subsequent step to isolate the steps of gradient descent.\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        # When using collaborative filtering, the cost function has three variables (instead of two)\n",
    "        # ...weights (W) bias (b) and features (X). Collaborative filtering deduces ALL of these.\n",
    "        cost_value = cofi_cost_func_vectorized(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    # Use the tape to retrieve the gradients/derivatives (with respect to X W and b)\n",
    "    # These derivatives will be used in the next line to perform one iteration of gradient descent.\n",
    "    gradients = tape.gradient( cost_value, [X, W, b] )\n",
    "\n",
    "    # Run one step of gradient descent; This updates the value of w (reducing the cost, stepping down a valley).\n",
    "    # Reminder on the process of gradient descent...the following steps happen at each iteration\n",
    "    #    - Calculate the derivative with respect to w and then update w by learning_rate * derivative\n",
    "    #    - Calculate the derivative with respect to b and then update b by learning_rate * derivative\n",
    "    #    - Calculate the derivative with respect to x and then update x by learning_rate * derivative (unique to collaborative filtering)\n",
    "    optimizer.apply_gradients( zip(gradients, [X, W, b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")\n",
    "\n",
    "\n",
    "# Expected output on first run: Training loss at iteration 180: 2902.1\n",
    "# NB: If you run this cell multiple times, the algorithm will continue to optimize the parameters and lower the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9aca6d-8ef3-44fb-a801-a8888e1bcc2f",
   "metadata": {},
   "source": [
    "## Predict reviews / Make recommendations\n",
    "\n",
    "We compute the ratings for all the movies and users and display the movies that are recommended. These are based on the movies and ratings entered as my_ratings[] above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13db6e11-44b5-47f9-a149-81d5d0584b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 4.49 for movie My Sassy Girl (Yeopgijeogin geunyeo) (2001)\n",
      "Predicting rating 4.48 for movie Martin Lawrence Live: Runteldat (2002)\n",
      "Predicting rating 4.48 for movie Memento (2000)\n",
      "Predicting rating 4.47 for movie Delirium (2014)\n",
      "Predicting rating 4.47 for movie Laggies (2014)\n",
      "Predicting rating 4.47 for movie One I Love, The (2014)\n",
      "Predicting rating 4.46 for movie Particle Fever (2013)\n",
      "Predicting rating 4.45 for movie Eichmann (2007)\n",
      "Predicting rating 4.45 for movie Battle Royale 2: Requiem (Batoru rowaiaru II: Chinkonka) (2003)\n",
      "Predicting rating 4.45 for movie Into the Abyss (2011)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.90 for Shrek (2001)\n",
      "Original 5.0, Predicted 4.84 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original 2.0, Predicted 2.13 for Amelie (Fabuleux destin d'AmÃ©lie Poulain, Le) (2001)\n",
      "Original 5.0, Predicted 4.88 for Harry Potter and the Chamber of Secrets (2002)\n",
      "Original 5.0, Predicted 4.87 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Original 5.0, Predicted 4.89 for Lord of the Rings: The Return of the King, The (2003)\n",
      "Original 3.0, Predicted 3.00 for Eternal Sunshine of the Spotless Mind (2004)\n",
      "Original 5.0, Predicted 4.90 for Incredibles, The (2004)\n",
      "Original 2.0, Predicted 2.11 for Persuasion (2007)\n",
      "Original 5.0, Predicted 4.80 for Toy Story 3 (2010)\n",
      "Original 3.0, Predicted 3.00 for Inception (2010)\n",
      "Original 1.0, Predicted 1.41 for Louis Theroux: Law & Disorder (2008)\n",
      "Original 1.0, Predicted 1.26 for Nothing to Declare (Rien Ã  dÃ©clarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases (trained in previous section)\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc97715-3afe-48e6-be50-5779a1f238c0",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Above, the predicted ratings for the first few hundred movies lie in a small range. We can augment the above by selecting from those top movies, movies that have high average ratings and movies with more than 20 ratings. This section uses a Pandas data frame which has many handy sorting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2132ea0-ab34-4721-afd6-d9c5c7836c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>mean rating</th>\n",
       "      <th>number of ratings</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>4.030961</td>\n",
       "      <td>4.252336</td>\n",
       "      <td>107</td>\n",
       "      <td>Departed, The (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>3.985281</td>\n",
       "      <td>4.238255</td>\n",
       "      <td>149</td>\n",
       "      <td>Dark Knight, The (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4.477798</td>\n",
       "      <td>4.122642</td>\n",
       "      <td>159</td>\n",
       "      <td>Memento (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>4.887054</td>\n",
       "      <td>4.118919</td>\n",
       "      <td>185</td>\n",
       "      <td>Lord of the Rings: The Return of the King, The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>4.796531</td>\n",
       "      <td>4.109091</td>\n",
       "      <td>55</td>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>4.357304</td>\n",
       "      <td>4.021277</td>\n",
       "      <td>188</td>\n",
       "      <td>Lord of the Rings: The Two Towers, The (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>4.004471</td>\n",
       "      <td>4.006494</td>\n",
       "      <td>77</td>\n",
       "      <td>Shaun of the Dead (2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>3.980649</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>Hot Fuzz (2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>4.084643</td>\n",
       "      <td>3.993421</td>\n",
       "      <td>76</td>\n",
       "      <td>Dark Knight Rises, The (2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>4.434171</td>\n",
       "      <td>3.989362</td>\n",
       "      <td>47</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>4.289676</td>\n",
       "      <td>3.960993</td>\n",
       "      <td>141</td>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>4.344999</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>81</td>\n",
       "      <td>Casino Royale (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>4.133481</td>\n",
       "      <td>3.943396</td>\n",
       "      <td>53</td>\n",
       "      <td>How to Train Your Dragon (2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>4.175743</td>\n",
       "      <td>3.887931</td>\n",
       "      <td>58</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>4.135287</td>\n",
       "      <td>3.871212</td>\n",
       "      <td>132</td>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>3.967900</td>\n",
       "      <td>3.869565</td>\n",
       "      <td>69</td>\n",
       "      <td>Avengers, The (2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>4.897137</td>\n",
       "      <td>3.867647</td>\n",
       "      <td>170</td>\n",
       "      <td>Shrek (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3.971892</td>\n",
       "      <td>3.836364</td>\n",
       "      <td>110</td>\n",
       "      <td>Crouching Tiger, Hidden Dragon (Wo hu cang lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>4.898892</td>\n",
       "      <td>3.836000</td>\n",
       "      <td>125</td>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>4.874936</td>\n",
       "      <td>3.778523</td>\n",
       "      <td>149</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4.843375</td>\n",
       "      <td>3.761682</td>\n",
       "      <td>107</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>4.021778</td>\n",
       "      <td>3.723684</td>\n",
       "      <td>76</td>\n",
       "      <td>X2: X-Men United (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4.242986</td>\n",
       "      <td>3.699248</td>\n",
       "      <td>133</td>\n",
       "      <td>X-Men (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>4.878342</td>\n",
       "      <td>3.598039</td>\n",
       "      <td>102</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (2002)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred  mean rating  number of ratings  \\\n",
       "1743  4.030961     4.252336                107   \n",
       "2112  3.985281     4.238255                149   \n",
       "211   4.477798     4.122642                159   \n",
       "929   4.887054     4.118919                185   \n",
       "2700  4.796531     4.109091                 55   \n",
       "653   4.357304     4.021277                188   \n",
       "1122  4.004471     4.006494                 77   \n",
       "1841  3.980649     4.000000                 61   \n",
       "3083  4.084643     3.993421                 76   \n",
       "2804  4.434171     3.989362                 47   \n",
       "773   4.289676     3.960993                141   \n",
       "1771  4.344999     3.944444                 81   \n",
       "2649  4.133481     3.943396                 53   \n",
       "2455  4.175743     3.887931                 58   \n",
       "361   4.135287     3.871212                132   \n",
       "3014  3.967900     3.869565                 69   \n",
       "246   4.897137     3.867647                170   \n",
       "151   3.971892     3.836364                110   \n",
       "1150  4.898892     3.836000                125   \n",
       "793   4.874936     3.778523                149   \n",
       "366   4.843375     3.761682                107   \n",
       "754   4.021778     3.723684                 76   \n",
       "79    4.242986     3.699248                133   \n",
       "622   4.878342     3.598039                102   \n",
       "\n",
       "                                                  title  \n",
       "1743                               Departed, The (2006)  \n",
       "2112                            Dark Knight, The (2008)  \n",
       "211                                      Memento (2000)  \n",
       "929   Lord of the Rings: The Return of the King, The...  \n",
       "2700                                 Toy Story 3 (2010)  \n",
       "653       Lord of the Rings: The Two Towers, The (2002)  \n",
       "1122                           Shaun of the Dead (2004)  \n",
       "1841                                    Hot Fuzz (2007)  \n",
       "3083                      Dark Knight Rises, The (2012)  \n",
       "2804  Harry Potter and the Deathly Hallows: Part 1 (...  \n",
       "773                                 Finding Nemo (2003)  \n",
       "1771                               Casino Royale (2006)  \n",
       "2649                    How to Train Your Dragon (2010)  \n",
       "2455      Harry Potter and the Half-Blood Prince (2009)  \n",
       "361                               Monsters, Inc. (2001)  \n",
       "3014                               Avengers, The (2012)  \n",
       "246                                        Shrek (2001)  \n",
       "151   Crouching Tiger, Hidden Dragon (Wo hu cang lon...  \n",
       "1150                            Incredibles, The (2004)  \n",
       "793   Pirates of the Caribbean: The Curse of the Bla...  \n",
       "366   Harry Potter and the Sorcerer's Stone (a.k.a. ...  \n",
       "754                             X2: X-Men United (2003)  \n",
       "79                                         X-Men (2000)  \n",
       "622      Harry Potter and the Chamber of Secrets (2002)  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter=(movieList_df[\"number of ratings\"] > 20)\n",
    "movieList_df[\"pred\"] = my_predictions\n",
    "movieList_df = movieList_df.reindex(columns=[\"pred\", \"mean rating\", \"number of ratings\", \"title\"])\n",
    "movieList_df.loc[ix[:300]].loc[filter].sort_values(\"mean rating\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
